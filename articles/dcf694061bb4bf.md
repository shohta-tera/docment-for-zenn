---
title: "KubernetesにApache Airflowをインストールする"
emoji: "🐡"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Kubernetes", "helm", "Airflow", "PostgreSQL"]
published: true
---

# はじめに

# 環境
- WSL2: Ver20
- Helm: v3.6.1

# 前回の記事

Kubernetesのクラスターは[前回の記事](https://zenn.dev/shorter/articles/324598676ea718)で記載しています。  
また、ClusterはKind(Kubernetes in Docker)で作成しています。

## PostgreSQLのインストール

- `database` namespaceの作成。
```
kubectl create namespace database
```

- chartレポジトリの追加
```
helm repo add bitnami https://charts.bitnami.com/bitnami
```

- install
```
helm upgrade --install postgresql bitnami/postgresql -n database
```

- 確認

POSTGRESQLのパスワードを環境変数に設定
``` 
export POSTGRES_PASSWORD=$(kubectl get secret --namespace database postgresql -o jsonpath="{.data.postgresql-password}" | base64 --decode)
```
データベースに接続
```
kubectl port-forward --namespace database svc/postgresql 5432:5432 &
    PGPASSWORD="$POSTGRES_PASSWORD" psql --host 127.0.0.1 -U postgres -d postgres -p 5432
```
Airflow用のロールとデータベースの設定
```
postgres=# CREATE DATABASE airflow;
postgres=# CREATE ROLE su_airflow WITH PASSWORD 'su_airflow';
postgres=# ALTER ROLE "su_airflow" WITH LOGIN;
postgres=# GRANT ALL PRIVILEGES ON DATABASE airflow TO su_airflow;
```

## MinIOのインストール

### MinIOの概要

[MinIO](https://min.io/)とは、Amazon S3のAPIと互換性をもった、オブジェクトストレージのOSSです。Airflowのアプリケーションログは、ElasticSearchやAmazon S3を使って、保存することができるのですが、Helmを用いてKubernetesローカル環境内で構築して、お金のかからず簡単にログを保管していきたいと思います。

### MinIOのインストール

基本的には、[公式](https://github.com/minio/operator/tree/master/helm/minio-operator)の手順をもとに実行していきます。

#### Helm repoの作成

`helm repo add minio https://helm.min.io/`

#### Chartのインストール

```
kubectl create namespace minio
helm upgrade --install minio --namespace=minio --set persistence.size=1Gi,accessKey=AirflowTest,secretKey=asdqwe123 minio/minio --values=values.yaml
```

#### Port forward
```
export POD_NAME=$(kubectl get pods --namespace minio -l "release=minio" -o jsonpath="{.items[0].metadata.name}") && \
kubectl port-forward $POD_NAME 9000 --namespace minio
```

#### Airflowのログのための準備

localhost:9000にアクセスします。  
![右下の方](https://storage.googleapis.com/zenn-user-upload/8a34c98f6cf4927c632dc0e2.png)
上図のように、Create Bucketがあるので、それを選択します。  
名前は今回は`airflow`としています。
![バケットポリシー](https://storage.googleapis.com/zenn-user-upload/8801446f13ff44756c864ba4.png)
作成したバケットに対してバケットポリシーを設定します。  
今回はすべてのPathに対して、`Read and Write`を設定する。  

## Airflow

### Airflowについて

Pythonで実装されているDAG(有向非巡回グラフ)で作成したジョブ管理ツールです。  
詳しい内容などは、DevelopersIOの記事などが非常に参考になりますので、記載しておき、今回は概要の説明はしません。
- https://dev.classmethod.jp/articles/airflow-gs-arch-learn/

また、今回使用するHelm Chartは[公式](https://github.com/airflow-helm/charts/tree/main/charts/airflow)のものではなく、[Bitnami](https://github.com/bitnami/charts/tree/master/bitnami/airflow)によるものを使用しています。理由としては、公式よりBitnami版のほうが更新頻度が高かったためです。

### Airflowのインストール

#### ディレクトリ構造

```
./
├── files
│   └── config
│       └── requirements.txt
├── secrets
│   └── secrets.yaml
└── values.yaml
```
secrets.yamlにはAirflowログイン時の認証情報とfernetKeyを、gitから取得する認証情報を設定する。

#### secrets.yaml

```
---
auth:
  username: su_airflow
  password: a1rfl0w@
  # python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
  fernetKey: uNJX4cU7e1HWupdeFOwoczu-q8f4jwl5rObZGk9F2jk=

git:
  dags:
    enabled: true
    repositories:
      - name: workflow
        repository: githubのレポジトリ情報。レポジトリアクセスのためのトークンも入る。
        branch: main
        path: src/dags
```

#### values.yaml

```
---

executor: KubernetesExecutor
redis:
  enabled: false
rbac:
  create: true
serviceaccount:
  create: true

postgresql:
  enabled: false
externalDatabase:
  host: postgresql-headless.database.svc.cluster.local
  user: su_airflow
  database: airflow
  port: 5432
extraEnvVars:
  - name: "AIRFLOW__API__AUTH_BACKEND"
    value: "airflow.api.auth.backend.basic_auth"
  - name: "AIRFLOW__WEBSERVER__EXPOSE_CONFIG"
    value: "True"
  - name: "AIRFLOW__CORE__LOAD_EXAMPLES"
    value: "False"
  - name: "GNICORN_CMD_ARGS"
    value: "--log-level WARNING"
  - name: "PYTHONPATH"
    value: "opt/bitnami/airflow/dags/git_workflow"
  - name: "AIRFLOW__LOGGING__REMOTE_LOGGING"
    value: "True"
  - name: "AIRFLOW__LOGGING__ENCRYPT_S3_LOGS"
    value: "False"
  - name: "AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER"
    value: "s3://airflow/logs"
  - name: "AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID"
    value: "local_minio"

web:
  replicaCount: 1
  extraVolumeMounts:
    - name: airflow-python-requirements
      mountPath: /bitnami/python/
  extraVolumes:
    - name: airflow-python-requirements
      configMap:
        name: airflow-python-requirements

scheduler:
  replicaCount: 1
  extraVolumeMounts:
    - name: airflow-python-requirements
      mountPath: /bitnami/python/
  extraVolumes:
    - name: airflow-python-requirements
      configMap:
        name: airflow-python-requirements

worker:
  extraVolumeMounts:
    - name: airflow-python-requirements
      mountPath: /bitnami/python/
  extraVolumes:
    - name: airflow-python-requirements
      configMap:
        name: airflow-python-requirements

metrics:
  enabled: true
```
主な設定項目は以下。
- executor: Kubernetes上で実行するがDAG実行時にPodを作成する`KubernetesExecutor`を指定しています。
- postgresql: 事前にインストールしたPostgreSQLを使用する想定です。
- extraEnvVars: 最低限必要な環境変数のみを設定しています。

#### Namespaceの作成

`kubectl creaate namespace jobs`

#### helm chartのインストール

このコマンド内で、PostgreSQLのパスワードを入れています。
```
helm upgrade airflow bitnami/airflow \
  --install \
  --namespace jobs \
  --values=./values.yaml \
  --values=./secrets/secrets.yaml \
  --set externalDatabase.password=su_airflow \
  --set web.image.tag=2.0.2-debian-10-r4 \
  --set scheduler.image.tag=2.0.2-debian-10-r13 \
  --set worker.image.tag=2.0.2-debian-10-r13 \
  --set metrics.image.tag=0.20210126.0-debian-10-r93 \
  --version 10.0.1
```

#### Port forwardの設定

`kubectl port-forward --namespace jobs svc/airflow 8080:8080`

localhost:8080にアクセスすると、下図のようなUIが表示されます。
![TOP](https://storage.googleapis.com/zenn-user-upload/6cf1f513dd5b0885744244fe.png)

AdminセクションのConnectionから、minio用の接続設定をします。
![](https://storage.googleapis.com/zenn-user-upload/17cdb6cbcfb349774fb83eab.png)
上図のように、設定する。
接続名はyamlで設定したものと同一のものを用いる。  
また、LoginとPasswordにはMinio作成時に設定したAccessKeyとSecretAccessKeyを用います。さらにHostには、minioのエンドポイントを指定します。

## おわりに

今回はAirflowをインストールして、基本的な設定までにしています。  
次回以降はDAGの書き方などについてかければと思っています。  

必要なファイルは[GitHub](https://github.com/shohta-tera/airflow)においています。